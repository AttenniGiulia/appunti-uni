
\chapter{Automi (modelli di calcolo)}

\index{automi}
Cosa \`e una computazione? Cosa \emph{calcola} un modello di calcolo?

Partiamo da classificare cosa \`e un problema.
Ci interesseremo solo di problemi decisionali (la cui risposta \`e un s\`i o un no).
\`E possibile passare da un algoritmo che risolve un problema decisionale a un algoritmo che trova la soluzione del problema.

Un'istanza di un problema \`e l'input del problema.

Abbiamo accennato che un problema decisionale identifica un linguaggio.
Un linguaggio \`e un insieme di parole, dove con parola indichiamo una combinazione di elementi di un alfabeto (finito) di simboli.
Il linguaggio associato al problema \`e quello delle stringhe che codificano istanze ``s\`i'' del problema (decisionale).

\begin{description}
	\item[Computazione] riconoscimento di una parola.
	\item[Algoritmo] macchina che riconosce un linguaggio.
	\item[Alfabeto] insieme finito di simboli.
	\item[Parola] sequenza di lettere di un alfabeto.
	\item[$\lambda$ (lambda) o $\emptystring$ (epsilon)] stringa vuota.
\end{description}

Se $\Sigma$ \`e un alfabeto, $\Sigma^{\star}$ \`e l'insieme di tutte le parole costruibili in quell'alfabeto
Un linguaggio $L$ su $\Sigma$ \`e un sottoinsieme di $\Sigma^{\star}$.

Per come abbiamo definito un'istanza di un problema, ogni parola \`e un'istanza.
Quindi un linguaggio \`e un insieme di parole che corrispondono a istanze s\`i di un dato problema.

Tutti i nostri modelli di calcolo sono riconoscitori di linguaggi.

\section{Automi a stati finiti}

\index{automi!a stati finiti}
Consideriamo automi senza output, che si limitano a riconoscere l'input.

In un FSA la testina si sposta sempre a destra di un passo.
L'automa \`e rappresentabile con un grafo diretto in cui ogni nodo \`e uno stato, e un arco etichettato da una lettera dell'alfabeto di input  indica che si pu\`o passare da uno stato all'altro con l'input indicato.
Lo stato iniziale \`e individuato da un arco entrante che viene dal nulla.
Gli stati finali sono evidenziati.

La lunghezza di un cammino \`e data dal numero di vertici (nodi) visitati.
Ogni nodo deve avere un arco uscente per ogni lettera dell'alfabeto.
Uno stato da cui non si esce, ossia da cui non si pu\`o raggiungere uno stato finale, \`e uno ``stato pozzo'', e pu\`o non essere disegnato.
Un automa accetta almeno una parola se c'\`e almeno un cammino dallo stato iniziale a uno degli stati finali

La formalizzazione degli automi a stati finiti \`e la solita.
Ci concentriamo in particolare, per adesso, sui DFA, o \emph{Deterministic Finite state Automata}.
Un DFA \`e una quintupla:
\[
	(Q, \Sigma, \delta, q_0. F)
\]
dove $Q$ \`e l'insieme degli stati, $\Sigma$ \`e l'alfabeto di input, $\delta : Q \times \Sigma \to Q$ \`e la funzione di transizione, $q_0 \in Q$ \`e lo stato iniziale e $F \subseteq Q$ \`e l'insieme di stati finali.

Parleremo spesso di configurazione: non tiene conto solo dello stato effettivo dell'automa, ma anche dello stato della sua memoria.
In un FSA non c'\`e memoria, ma ci interessa tenere conto della stringa ancora da leggere.

La configurazione di partenza \`e $(q_0, x)$, con $x \in \Sigma^{\star}$ a indicare la stringa di input.

Definiamo la relazione ``porta a'' come segue:
\[
	(p, ax) \underset{M}{\to} (q,x) \iff \delta(p,a) = q
\]
dove $p,q \in Q$ sono due stati, $a \in \Sigma$ \`e una lettera dell'alfabeto e $x \in \Sigma^{\star}$ \`e una stringa.

Notare: questa relazione \`e definita sull'insieme delle configurazioni.

La chiusura transitiva e riflessiva di questa relazione ci dice se da una certa configurazione arriviamo a un'altra.
Per chiusura transitiva, ricordiamo, si intende che le due coppie $((p, abx), (q,bx))$ e $((q,bx),(t,x))$ nella relazione portano alla coppia $((p,abx),(t,x))$ nella chiusura transitiva della relazione stessa.
La riflessivit\`a, invece, serve a dirci che senza input la macchina non cambia stato.

Una parola $x$ \`e accettata da $M$ se $(q_0, x) \underset{M}{\to} (q,\emptystring)$ con $q \in F$.
L'insieme delle parole accettate formano il linguaggio associato a $M$.

Possiamo estendere la funzione di transizione $\delta : Q \times \Sigma \to Q$ a una funzione $\delta^{\star}: Q \times \Sigma^{\star} \to Q$ definita come:
\begin{itemize}
	\item se $\abs{x} = 0$, allora $\delta^{\star}(q,x) = q$.
	\item se $\abs{x} > 0$, allora $x = ya$ dove $y \in \Sigma^{\star}$ e $a \in \Sigma$, e quindi $\delta^{\star}(q,x) = \delta \left( \delta^{\star} (q, y), a \right)$.
\end{itemize}

Segue immediatamente che:
\[
	\delta^{\star}(q,a) = \delta \left( \delta^{\star} (q, \emptystring) , a \right) = \delta (q,a)
\]
Inoltre, una definizione alternativa di ``accettare una parola'' \`e dire che:
\[
	\delta^{\star} (q_0, x) = r \in F
\]
La funzione $\delta^{\star}$, dato un input, ci porta nello stato a cui il DFA arriva consumando tutto l'input.

Possiamo formalizzare il linguaggio accettato da un DFA come segue:
\[
	\lang{M} = \{ x \in \Sigma^{\star} \text{ t.c. } \delta^{\star} (q_0, x) \in F \}
\]
E ora, pensiamo alla \emph{classe} dei linguaggi accettati dai DFA.

Un DFA accetta almeno una parola se esiste un cammino da $q_0$ a uno stato in $F$.
Se vogliamo trovare una parola accettata a forza bruta, prendiamo tutte le parole di lunghezza strettamente minore di $n$, dove $n$ \`e il numero degli stati dell'automa, e le proviamo tutte.

Supponiamo nessuna di queste parole sia accettata, e che esista una parola $w$ con $\abs{w} \ge n$ che viene accettata.
Per almeno uno stato passiamo due volte.
La parte di cammino che passa fra i due vertici ripetuti pu\`o essere tolta, e da $w$ possiamo togliere i caratteri che hanno portato a compiere questo ciclo.
Otteniamo quindi una parola $w'$ accettata dall'automa con $\abs{w'} < \abs{w}$.
Iterando il procedimento finch\'e la parola non \`e pi\`u corta di $n$, arriviamo all'assurdo.
Quindi se l'automa accetta almeno una parola, esiste una parola pi\`u corta di $n$ che viene accettata.

Con un altro giro di parole, se abbiamo un cammino di accettazione che ha un ciclo, togliendo le ``etichette'' relative al ciclo otteniamo una parola che \`e ancora accettata ma il cui cammino di accettazione non ha cicli e che quindi \`e lungo meno di $n$.

\subsection{Propriet\`a dei linguaggi dei DFA}

Ogni modello di calcolo ha delle propriet\`a.
I linguaggi dei DFA godono della propriet\`a di chiusura rispetto ad alcune operazioni.
I linguaggi sono insiemi, quindi abbiamo le tipiche operazioni di unione, intersezione e complemento.
In generale, i linguaggi sono chiusi rispetto a queste operazioni.

Un'altra operazione possibile \`e la concatenazione fra parole, che ci porta a pensare all'operazione di concatenazione \emph{fra linguaggi}: concateniamo tutte le parole del primo con tutte le parole del secondo.
Si indica tipicamente con $L L'$.
Due propriet\`a banali:
\[
	\{ \emptystring \} L = L = L \{ \emptystring \} \qquad \emptyset L = \emptyset = L \emptyset
\]
La concatenazione ci porta poi a definire il concetto di potenza di un linguaggio (ripetizione della concatenazione).
Il ``caso base'' \`e $L^0 = \{ \emptystring \}$.

Il simbolo ``stella di Kleene'' indica l'unione di tutte le potenze di un linguaggio:
\[
	L^{\kleenestar} = \{ \emptystring \} \cup L \cup L^2 \cup L^3 \cup \dots = \bigcup_{n \ge 0} L^n
\]

Un insieme $C$ \`e chiuso rispetto all'operazione (binaria) $\cdot$ se $\forall x, y \in C$, vale che $x \cdot y \in C$.

Vogliamo dimostrare (o comunque vedere) che $\langs{\text{DFA}}$, o classe dei linguaggi regolari, ossia l'insieme di tutti i linguaggi accettati da una qualche DFA, \`e chiuso rispetto alle operazioni di unione, intersezione, complemento, concatenazione e stella di Kleene.

\begin{itemize}
	\item $L, L' \in \langs{\text{DFA}} \implies L \cup L' \in \langs{\text{DFA}}$.
		La nuova macchina che accetta l'unione dei due linguaggi possiamo costruirla a partire dalle due macchine $M_1, M_2$.
		Date le due DFA:
		\[
			M_1 = (Q_1, \Sigma, \delta_1, q_{01}, F_1) \qquad M_2 = (Q_2, \Sigma, \delta_2, q_{02}, F_2)
		\]
		Costruiamo la macchina che accetta l'unione in questo modo:
		\[
			M = \left( (Q_1 \times Q_2), \Sigma, \delta, (q_{01}, q_{02}), F \right)
		\]
		L'insieme degli stati \`e il prodotto cartesiano degli stati delle due macchine.
		Dove la nuova funzione \`e definita come $\delta \left( (q_1, q_2), a \right) = \left( \delta_1(q_1, a), \delta_2(q_2, a) \right)$, e l'insieme degli stati finali $F$ \`e dato dall'unione $F_1 \times Q_2 \cup Q_1 \times F_2$.
	\item $L, L' \in \langs{\text{DFA}} \implies L \cap L' \in \langs{\text{DFA}}$.
		La costruzione \`e identica a quella per l'unione, con la differenza che l'insieme degli stati finali \`e ora dato da $F_1 \times F_2$.
	\item $L \in \langs{\text{DFA}} \implies \complement L \in \langs{\text{DFA}}$.
		Il complemento di $M = (Q, \Sigma, \delta, q_0, F)$ \`e dato da $\complement M = (Q, \Sigma, \delta, q_0, Q \setminus F)$.
\end{itemize}

Si dimostra quindi per induzione, per l'unione e l'intersezione, che:
\[
	\delta^{\star} \left( ( q_{01}, q_{02}), x \right) = \left( \delta_1^{\star} (q_{01}, x), \delta_2^{\star} (q_{02}, x) \right)
\]
Non ci interessa degli stati non raggiungibili dallo stato iniziale.

Per il complemento, invece, la prova \`e immediata:
\[
	\left( x \in \lang{M} \iff \delta^{\star} (q_0, x) \in F \right) \equiv \left( x \in \lang{\complement M} \iff \delta^{\star} (q_0, x) \in Q \setminus F \right)
\]

\subsection{Automi non deterministici (NFA)}

\index{automi!a stati finiti!non deterministici}
Con i NFA da uno stato, con un input, possiamo raggiungere pi\`u stati.
Se fra tutti i cammini individuati da una parola ce ne \`e uno che termina con uno stato finale, l'automa accetta la parola.
Con i NFA introduciamo anche le $\emptystring$-transizioni o $\emptystring$-mosse, che non hanno bisogno di una parola in input.

Non determinismo significa che possiamo avere cammini diversi con lo stesso input, ossia l'input non determina il cmamino.

Si possono introdurre le $\emptystring$-transizioni anche nelle DFA, ma gli stati con $\emptystring$-transizioni non devono avere altre transizioni possibili.

La formalizzazione degli NFA \`e praticamente identica:
\[
	M = (Q, \Sigma, \delta, q_0, F)
\]
Ma adesso la funzione di transizione \`e una funzione $\delta : Q \times \left( \Sigma \cup \{ \emptystring \} \right) \to \parts{Q}$.
Non porta a un singolo stato, ma a un insieme di stati.

Il concetto di configurazione \`e identico, ma un automa pu\`o avere pi\`u configurazioni.
Vale ancora la relazione definita per i DFA.
\[
	(p, ax) \underset{M}{\to} (q,x) \iff q \in \delta(p,a)
\]
Una configurazione \`e di accettazione se \`e $(q, \emptystring)$ con $q \in F$.

Una parola \`e rifiutata da un NFA quando non esistono cammini di accettazione, ossia tutti i cammini si bloccano prima della fine dell'input o terminano in uno stato non in $F$.

\subsection{Equivalenza fra NFA e DFA}

Abbiamo un algoritmo per creare un DFA a partire da un NFA, che ne dimostra quindi l'equivalenza.
Con $\emptystring$-chiusura di uno stato $q$ indichiamo l'insieme degli stati raggiungibili da $q$ usando solo $\emptystring$-mosse.

\begin{algorithm}
	\caption{Algoritmo per creare un DFA a partire da un NFA.}
	\label{alg:algoritmo_dfa_eq_nfa}
	\begin{algorithmic}
		\Require un NFA con $\emptystring$-mosse $M = (Q, \Sigma, \delta, q_0, F)$
		\Ensure un DFA $M' = (Q', \Sigma, \delta', q_0', F')$ equivalente
		\State $Q' \gets \{ \emptystring$-chiusura($q_0$)$\}$
		\While{$\exists T \in Q'$ non marcato}
			\State marca $T$
			\ForAll{$a \in \Sigma$}
				\State $V \gets \bigcup_{q \in T} \delta(q, a)$
				\State $V' \gets \bigcup_{q \in V}$ $\emptystring$-chiusura($q$)
				\If{$V' \notin Q'$}
				\State $Q' \gets Q' \cup \{ V' \}$
				\EndIf
				\State $\delta'(T, a) \gets V'$
			\EndFor
		\EndWhile
	\end{algorithmic}
\end{algorithm}

Lo stato iniziale, dopo aver usato l'algoritmo \ref{alg:algoritmo_dfa_eq_nfa}, sar\`a l'$\emptystring$-chiusura di $q_0$.
Gli stati finali in $F'$ saranno tutti gli stati in $Q'$ che contengono uno stato $q \in F$.

La complessit\`a dell'algoritmo \`e un problema: potremmo essere costretti a creare $2^n$ nuovi stati.
Prendiamo ad esempio l'automa in figura \ref{fig:nfa_con_problemi}.
Questo automa accetta tutte le stringhe con un 1 nella posizione $n$-ultima (o una cosa simile).
Il DFA di questo automa ha $2^n$ stati.

\begin{figure}
	\centering
	\begin{tikzpicture}[
			->,
			>=stealth',
			shorten >=1pt,
			auto,
			node distance=2.8cm,
			semithick
		]

		\node[initial, state] (q0) {$q_0$};
		\node[state] (q1) [right of=q0] {$q_1$};
		\node[state] (q2) [right of=q1] {$q_2$};
		\node[] (dots) [right of=q2] {$\dots$};
		\node[state, accepting] (qn) [right of=dots] {$q_n$};

		\path (q0)	edge [loop, above]	node {0,1}	(q0)
			(q0)	edge	node {1}	(q1)
			(q1)	edge	node {0,1}	(q2)
			(q2)	edge	node {0,1}	(dots)
			(dots)	edge	node {0,1}	(qn);
	\end{tikzpicture}
	\caption{Automa con problemi}
	\label{fig:nfa_con_problemi}
\end{figure}

Bisognerebbe dimostrare l'equivalenza fra l'automa che costruiamo con l'algoritmo e l'automa iniziale, ossia che:
\[
	x \in \lang{M} \iff x \in \lang{M'}
\]
Ma chi siamo noi per dimostrarlo?

\subsection{\emph{Pumping Lemma}}

Abbiamo parlato di cicli nei cammini di parole accettate.
Siamo sicuri che c'\`e un ciclo nel cammino di una parola accettata, quando la parola \`e pi\`u lunga di $n = \abs{Q}$.
Ogni parola pi\`u lunga di $n$ si pu\`o scomporre in tre sottoparole: la parola dall'inizio a prima del ciclo, il ciclo, e la fine della parola.
Sicuramente l'etichetta del ciclo \`e non vuota.

Possiamo quindi scomporre una parola $w$ come la concatenazione delle tre parole $xyz$, con $\abs{y} > 0$.
Da questa scomposizione possiamo ricavare infinite parole $x y^i z$, ``percorrendo'' pi\`u volte il ciclo.

Con il \emph{pumping lemma} dimostriamo che esiste un linguaggio che non \`e regolare (ossia per cui non esiste un automa a stati finiti che lo riconosca).

Partiamo dal fatto che ogni parola accettata pi\`u lunga del numero degli stati contiene un ciclo.
Possiamo ricavare infinite parole ripetendo le etichette relative al ciclo.
Questo vale \emph{per ogni} parola accettata pi\`u lunga del numero degli stati, e per qualsiasi numero di volte ripetiamo le etichette del ciclo.

Per dimostrare, grazie al pumping lemma, che un certo linguaggio non \`e regolare, dobbiamo far vedere che non esiste una macchina che lo accetti.
Quindi per ogni possibile numero $k$ di stati troviamo una parola dentro il linguaggio che \`e pi\`u lunga di $k$ ma che non rispetta il pumping lemma.
Quindi per ogni sottoparola non vuota che termina entro il $k$-esimo carattere troviamo un indice $i$ tale che, ripetendo la sottoparola $i$ volte, otteniamo una parola non nel linguaggio.

\`E come se fissassimo di volta in volta il numero di nodi nell'ipotetico automa, e trovassimo una parola che, essendo pi\`u lunga del numero di nodi, dovrebbe contenere un ciclo.
Ma il ciclo non c'\`e, perch\'e ogni sottoparola candidata a esserlo, se iterata un certo numero di volte, ci porta fuori dal linguaggio.
Questo contraddice il pumping lemma: percorrendo il ciclo un numero arbitrario di volte otteniamo sempre parole nel linguaggio.

\begin{theorem}
	Un linguaggio $L$ non \`e regolare se $\forall k > 0$ $\exists z \in L : z \ge k$, e per ogni fattorizzazione di $z = u v w$ con $\abs{v} \ge 1$ e $\abs{uv} \le k$ $\exists i \ge 0$ tale che $u v^i w \notin L$.
\end{theorem}

\section{Automa a pila (\emph{Push-Down Automata})}

I PDA sono automi a stati finiti con una pila.
\`E possibile accedere a una memoria, che funziona come uno stack, ma a cui possiamo accedere solo al \emph{top}.
Come in tutte queste astrazioni, la pila \`e infinita.

Formalmente un automa a pila \`e una sestupla:
\[
A = ( Q, \Sigma, \Gamma, \Delta, q_0, F )
\]
dove $Q$ \`e un insieme finito di stati, $\Sigma$ \`e un alfabeto finito di input, $\Gamma$ \`e l'alfabeto finito della pila, $\Delta : Q \times \Sigma' \times \Gamma' \to \parts{ Q \times \Gamma' }$ \`e la funzione di transizione, dove $\Sigma' = \Sigma \cup \{ \emptystring \}$ e $\Gamma' = \Gamma \cup \{ \emptystring \}$, $q_0 \in Q$ \`e lo stato iniziale e $F \subseteq Q$ \`e l'insieme degli stati finali.

Due cose da notare: la funzione di transizione, nella definizione, \`e non deterministica, poich\'e porta a un insieme delle parti.
Poi, la funzione di transizione \`e definita a partire da uno stato, un carattere di input (anche vuoto), e un carattere sulla pila (anche vuoto), e porta a un insieme di coppie stato, carattere sulla pila.
\`E confuso, finch\'e non si vede cosa \`e una configurazione.

La configurazione di un automa a pila \`e dato da tre cose:
\begin{itemize}
	\item stato della macchina
	\item input ancora da leggere
	\item stato della pila.
\end{itemize}
Quindi la configurazione \`e un elemento di $Q \times \Sigma^{\star} \times \Gamma^{\star}$. Un esempio pu\`o essere $(q, aaabb, CA\stackend)$.
Il simbolo pi\`u a sinistra nella pila \`e la cima della pila ($C$ nel nostro caso).

Supponiamo $(q, C) \in \Delta(p, a, B)$, e definiamo una relazione simile a quella vista con i DFA sulla configurazione di un automa.
Diciamo quindi che $(p, ax, B\alpha) \leadsto (q, x, C\alpha)$, con $x \in \Sigma^{\star}$ a indicare l'input rimanente e $\alpha \in \Gamma^{\star}$ a indicare il resto della pila.
Nello stato $p$, con input $a$ e con $B$ sulla cima della pila, andiamo nello stato $q$ sostituendo $C$ a $B$ sulla pila.
Quindi la pila passa da una configurazione a un'altra consumando un carattere di input, cambiando stato, e modificando il carattere in cima alla pila (ossia, il carattere pi\`u a sinistra).

\`E possibile usare delle $\emptystring$-transizioni per aggiungere o togliere caratteri della pila.
Se, nell'esempio di prima, $B = \emptystring$ e $C \neq \emptystring$, stiamo facendo ``push''.
Se invece $B \neq \emptystring$ e $C = \emptystring$, stiamo facendo ``pop''.
Ogni stringa (di input o della pila) possiamo pensarla come il carattere di stringa vuota concatenato alla stringa stessa!

Anche i PDA si distinguono in PDA deterministici e PDA non deterministici.
Un PDA $ = (Q, \Sigma, \Gamma, \Delta, q_0, F )$ \`e deterministico se valgono le due condizioni seguenti:
\begin{enumerate}
	\item $\forall q \in Q$, $a \in \Sigma'$, $B \in \Gamma'$, vale che $\abs{\Delta(q,a,B)} \le 1$, ossia dato uno stato, un elemento in cima alla pila, e un carattere di input, la funzione di transizione porta al pi\`u in uno stato.
	\item $\forall q \in Q$, $B \in \Gamma'$, vale che:
	\[
	\Delta(q, \emptystring, B) \neq \emptyset \implies \Delta(q, a, B) = \emptyset \forall a \in \Sigma
	\]
	Ossia, dato uno stato e un elemento in cima alla pila, se esiste una $\emptystring$-transizione sull'input da quello stato, la funzione di transizione non \`e definita per ogni altro input in $\Sigma$.
\end{enumerate}

Il linguaggio $\lang{A} = \{ a^n b^n : n \ge 0 \}$ \`e deterministico.
Invece, il linguaggio $Pal = \{ x : x = x^R \}$, ossia il linguaggio delle parole palindrome, non \`e deterministico.

I linguaggi dei PDA deterministici \emph{sono meno} dei linguaggi dei PDA non deterministici, ossia $\langs{\text{DPDA}} \subset \langs{\text{PDA}}$.

\subsection{Grammatiche libere dal contesto}

Vediamo un esempio prima di formalizzare le \emph{Context-Free Grammars}.
La grammatica delle espressioni aritmetiche \`e la seguente:
\begin{align*}
	E &\to E + E \\
	E &\to E \times E \\
	E &\to ( E ) \\
	E &\to id
\end{align*}
Con $id$ intendiamo un ``identificatore'', sia questo una variabile o un numero, e \`e un simbolo ``terminale'': non abbiamo una regola per rimpiazzarlo.
Stesso discorso per i simboli $+$, $\times$, $($ e $)$.

Una CFG \`e una grammatica generativa: possiamo usare le sue regole per generare stringhe nel linguaggio, ad esempio con la precedente possiamo generare l'espressione aritmetica $id + ( id \times id )$.
A cosa serva \`e e rimarr\`a un mistero.

Intuitivamente, i linguaggi delle PDA possiamo riscriverli come grammatiche libere dal contesto. Questa, ad esempio, \`e la grammatica di $a^n b^n$ con $n \ge 0$:
\begin{align*}
	G_1 : S \to aSb \langor \emptystring
\end{align*}
Questa, invece, \`e la grammatica del \emph{linguaggio delle parentesi bilanciate}, arrivato secondo nella classifica delle cose pi\`u inutili al mondo:
\begin{align*}
	G_2 : \ & S \to LSR \langor SS \langor LR \\
	& L \to ( \\
	& R \to )
\end{align*}

Formalizziamo.
Una grammatica libera dal contesto \`e una quadrupla $CFG = (T, V, S, F)$ (l'ordine sembra essere abbastanza libero qui), dove:
\begin{itemize}
	\item $T$ e $V$ sono due insiemi (finiti) rispettivamente di ``terminali'' e di ``variabili'',
	\item $S$ \`e un simbolo di ``start'', con $S \in V$ (ossia \`e una variabile),
	\item $P$ \`e un insieme di ``regole di produzione'' del tipo $A \to y$, dove $A \in V$ e $y \in {(T \cup V)}^{\star}$, ossia $y$ \`e una serie di terminali e non terminali.
\end{itemize}

Una regola di derivazione $B \to v$ \`e applicabile a $x$, con $x \in {(T \cup V)}^{\star}$ ossia stringa di terminali e non terminali, se $B$ \`e in $x$, ossia se $x = y B z$ con $y, z \in {(T \cup V)}^{\star}$ anche loro stringhe di terminali e non terminali.

Il risultato dell'applicazione di $B \to v$ a $x$ \`e la stringa $y v z$.
Possiamo chiudere questo insieme di regole di derivazione transitivamente e riflessivamente, ottenendo quindi regole come $y B z \to y v z$.

Attenzione: la grammatica \`e libera dal contesto perch\'e le regole di produzione non dipendono da cosa \`e attorno al non terminale (che \`e il contesto).
Regole simili non sono libere dal contesto:
\begin{align*}
	a B & \to v \\
	b B & \to w
\end{align*}

\subsubsection{Esempi di linguaggi e grammatiche}

Consideriamo il linguaggio $\lang{G} = \{ a^m b^n \text{ t.c. } m \ge n \ge 0 \}$.
Qual \`e la grammatica per generare questo linguaggio?
\begin{align*}
	S &\to aSb \langor aA \langor \emptystring \\
	A &\to aA \langor \emptystring
\end{align*}

Passiamo al linguaggio $\lang{G} = \{ a^i b^j c^k \text{ t.c. } i = j \lor j = k \text{ con } i,j,k \ge 0 \}$.
La sua grammatica \`e:
\begin{align*}
	S &\to AT \langor RC \langor \emptystring \\
	A &\to aA \langor \emptystring \\
	C &\to Cc \langor \emptystring \\
	T &\to bTc \langor \emptystring \\
	R &\to aRb \langor \emptystring
\end{align*}
Come sappiamo che questo \`e corretto?
La grammatica $A$ descrive il linguaggio $\lang{A} = \{ a^n : n \ge 0 \}$, cos\`i come la grammatica $C$ descrive il linguaggio $\lang{C} = \{c^n : n \ge 0\}$.
Questi due sono linguaggi regolari.
Le altre due grammatiche descrivono rispettivamente i linguaggi $\lang{T} = \{ b^i c^i : i \ge 0 \}$ e $\lang{R} = \{ a^i b^i : i \ge 0 \}$.
Quindi il nostro linguaggio \`e dato da $\lang{G} = \lang{A}\lang{T} \cup \lang{R}\lang{C}$.

Questo \`e un linguaggio \emph{inerentemente ambiguo}.
Non si pu\`o trovare una grammatica non ambigua equivalente.

Passiamo al linguaggio $\lang{G} = \{ a^i b^j c^k \text{ t.c. } i + j = k \text{ con } i,j,k \ge 0 \}$.
\begin{align*}
	S &\to aSc \langor B \langor \emptystring \\\
	B &\to bBc \langor \emptystring
\end{align*}

Passiamo al linguaggio in cui ogni prefisso di ogni parola ha un numero di $a$ maggiore o uguale al numero delle $b$.
Come troviamo la grammatica di questo linguaggio?
\begin{align*}
	S &\to aSbS \langor aA \langor \emptystring \\
	A &\to aA \langor \emptystring
\end{align*}

\subsubsection{Corrispondenza fra CFG e PDA}

I linguaggi liberi dal contesto corrispondono ai linguaggi riconosciuti dagli automi a pila.
Partendo da una grammatica, costruiamo un PDA che lavora non deterministicamente in tempo lineare per riconoscere la parola di input.

Sia $G = (T, V, S, P)$ una grammatica libera dal contesto, costruiamo l'automa a pila $(\{q_0, q, q_f\}, \, T, \, V \cup T \cup \{ \stackend \}, \, \Delta, \, q_0, \, \{q_f\})$ come segue:
\begin{enumerate}
	\item passiamo da $q_0$ a $q$ senza consumare input e impilando il simbolo di pila vuota $\stackend$ e il simbolo di start $S$,
	\item creiamo la funzione di transizione a partire dalle regole di produzione: senza consumare input, se in cima alla pila c'\`e una variabile $A$, sostituiamo $A$ con la parte destra di una regola di produzione con $A$ a sinistra; se in cima alla pila c'\`e un terminale $a$, creiamo una transizione che consuma $a$ in input e fa \emph{pop} di $a$ dalla cima della pila. Entrambi i tipi di transizione non cambiano stato (restano quindi in $q$),
	\item creiamo la transizione che non consuma input e che, con il simbolo $\stackend$ in cima alla pila, lo rimuove e va nello stato $q_f$.
\end{enumerate}
Attenzione: la regola di produzione $A \to B \langor C \langor D$ \`e equivalente alle tre regole $A \to B$, $A \to C$, $A \to D$.

Pi\`u formalmente, definiamo $\Delta$ come segue:
\begin{enumerate}
	\item $\Delta( q_0, \emptystring, \emptystring ) = \{ (q, \emptystring, S \stackend )\}$,
	\item $\forall A \to y \in P$, $\Delta (q, \emptystring, A) \ni (q, y)$,
	\item $\forall a \in T$, $\Delta (q, a, a) \ni (q, \emptystring)$.
	\item $\Delta (q, \emptystring, \stackend) = \{ (q_f, \emptystring, \emptystring ) \}$.
\end{enumerate}

% TODO sistemare da qui

Si pu\`o rimpiazzare una grammatica ambigua con una grammatica non ambigua equivalente.
Una grammatica \`e ambigua se ha pi\`u alberi di derivazione per uno stesso input.

Il metodo che usiamo \`e quello di imporre una precedenza e l'associativit\`a a sinistra.
\begin{verbatim}
E -> E + T | T
T -> T * F | F
F -> (E) | id
\end{verbatim}
Abbiamo tolto l'ambiguit\`a a questa grammatica:
\begin{verbatim}
E -> E + E
E -> E * E
E -> (E)
E -> id
\end{verbatim}
Date le grammatiche $G_1$ e $G_2$, vediamo che i linguaggi generati sono chiusi rispetto alle solite operazioni.
\begin{align*}
	G_1 \cup G_2 & : S \to S_1 \langor S_2 \\
	G_1 G_2 & : S \to S_1 S_2 \\
	G_1^{\star} & : S \to S S_1 \langor \emptystring
\end{align*}
I linguaggi liberi dal contesto non sono chiusi rispetto all'intersezione.
Consideriamo i linguaggi $a^n b^n c^m$ e $a^m b^n c^n$.
La loro intersezione \`e il linguaggio $a^n b^n c^n$ e non \`e un linguaggio libero dal contesto.
Ci\`o implica che i linguaggi context-free non sono chiusi neanche rispetto al complemento, poich\'e l'intersezione si pu\`o esprimere in termini di unione e complemento.

Il linguaggio $\{ ww : w \in \{0,1\}^{\star}\}$ non \`e context-free, ma il suo complemento s\`i.

Il suo complemento \`e l'unione del linguaggio delle parole di lunghezza dispari (banale) e del linguaggio delle parole di lunghezza pari le cui due met\`a non sono uguali.
\[
	L_1 = \{ xy : x,y \in \{0,1\}^{\star} \land \abs{x} = \abs{y} \land x \neq y \}
\]
Possiamo considerare solo parole del tipo $xax'za'z'$, con $x,z,x',z' \in \{0,1\}^{\star}$, e $a \neq a'$ elemento di $\{0,1\}$, e con $\abs{x} = \abs{x'}$ e $\abs{z} = \abs{z'}$.
Notare che le stringhe $xax'$ e $za'z'$ hanno lunghezza dispari.
Quindi $L_1$ \`e l'unione dei due linguaggi dati uno dalla concatenazione di $\{ x0z : \abs{x} = \abs{z} \}$ e $\{ x1z : \abs{x} = \abs{z} \}$ e l'altro dalla concatenazione di $\{ x1z : \abs{x} = \abs{z} \}$ e di $\{ x0z : \abs{x} = \abs{z} \}$.

Scrivendolo come grammatica, abbiamo che $G_1$ \`e:
\begin{align*}
G_1 :& S \to S_0 S_1 \langor S_1 S_0 \\
& S_0 \to 0 \langor 0 S_0 0 \langor 0 S_0 1 \langor 1 S_0 0 \langor 1 S_0 1 \\
& S_1 \to 1 \langor 0 S_1 0 \langor 0 S_1 1 \langor 1 S_1 0 \langor 1 S_1 1
\end{align*}

\section{\emph{Linear bound automata}}

Sono una versione limitata delle macchine di Turing.


\section{Macchina di Turing}

Le macchine di Turing sono un'astrazione di quello che fa una persona quando fa un calcolo.
Ha un nastro infinito a disposizione, su cui trova l'input e su cui pu\`o scrivere.

Una macchina di Turing non usa mai un'infinit\`a di caselle del nastro.
Si pu\`o semplificare la descrizione di una macchina aggiungendo mosse in cui la macchina non muove la testina, o aggiungendo uno stato di rifiuto e uno stato di accettazione, e via dicendo.
Dagli stati di accettazione e di rifiuto non sono possibili altre mosse.

Macchine di Turing deterministiche e non deterministiche sono equivalenti.

Il modello formale di una macchina di Turing \`e il seguente.
\[
	M = (Q, \Sigma, \Gamma, \Delta, q_0, q_a, q_r)
\]
$Q$ \`e l'insieme degli stati, $\Sigma$ \`e l'insieme dell'alfabeto di input, $\Gamma$ \`e l'insieme dell'alfabeto ``di nastro'', quindi $\Gamma \supset \Sigma$ e contiene altri elementi come il carattere di fine o di inizio stringa.
La funzione di transizione \`e una funzione totale non definita su $q_a, q_r$, ossia \`e $\Delta : Q \times \Gamma \to Q \times \Gamma \times \{L, R\}$.
$q_a$ e $q_r$ sono lo stato di accettazione e lo stato di rifiuto.

Una configurazione deve mantenere informazioni sul contenuto del nastro, sullo stato della macchina e sulla posizione della testina sul nastro.
Chiamiamo la configurazione $\alpha q a \rho$, elemento di $\Gamma^{\star} Q \Gamma^{\star}$, dove $\alpha$ e $\rho$ sono stringhe di $\Gamma$, $a$ \`e un carattere di $\Gamma$, e $q$ \`e uno stato.
Stiamo dicendo che il contenuto del nastro \`e la stringa $\alpha a \rho$, che ci troviamo nello stato $q$, e stiamo per leggere il carattere $a$.
La configurazione iniziale \`e $q_0 x$, se $x$ \`e la stringa di input.

Se una mossa ci porta a destra, ossia se $\delta(q, a) = (p, b, R)$, allora $\alpha q a c \rho \leadsto \alpha b p c \rho$.
Viceversa, se una mossa ci porta a sinistra, ossia se $\delta(q,c) = (p,b,L)$, allora $\alpha a q c \rho \leadsto \alpha p a b \rho$.

Una configurazione $\alpha q_a \beta$ \`e una configurazione di accettazione: non importa se dobbiamo leggere ancora parte della stringa.
$\alpha q_r \beta$ \`e invece una configurazione di rifiuto.

Il linguaggio accettato da una macchina di Turing \`e definito come:
\[
\lang{M} = \{ x : x \in \Sigma^{\star} \text{ e } q_0 x \leadsto \alpha q_a \beta \text{ per } \alpha, \beta \in \Gamma^{\star} \}
\]
Possiamo parlare anche di linguaggio rifiutato dalla macchina $R(M)$.
L'unione di $\lang{M}$ e $R(M)$, per\`o, non \`e sempre tutto $\Sigma^{\star}$.

Nel caso in cui l'unione dei due linguaggi dia tutto $\Sigma^{\star}$, diciamo che il linguaggio \`e \emph{deciso} dalla macchina.
Nel caso in cui su alcuni input la macchina non si ferma, si parla di linguaggio riconosciuto (riconoscibile).

$\langs{\text{TM}}$ \`e l'insieme dei linguaggi accettati da una macchina di Turing.

La tesi di Church - Turing dice che tutto quel che \`e generalmente ritenuto calcolabile, \`e calcolabile con una macchina di Turing.
Equivale a dire che i linguaggi riconosciuti dalle macchine di Turing sono i linguaggi dei problemi risolvibili.

Un algoritmo corrisponde a una macchina di Turing che si ferma sempre, un semialgoritmo si ferma solo sulle istanze ``no'' di un problema.

Aggiungere nastri alla macchina di Turing non ne aumenta il potere computazionale.

Si parla di complessit\`a solo quando la macchina si ferma sempre.

Una macchina di Turing con $k$ nastri la definiamo come la precedente, con la differenza della funzione di transizione:
\[
\delta Q \setminus \{q_a, q_r\} \times \Gamma^k \to Q \times \Gamma^k \times \{ L, R \}^{k}
\]
La configurazione la possiamo rappresentare con una stringa in $(\Gamma^{\star}Q\Gamma^{\star})^{k}$, ossia stringhe del tipo $\alpha_1 q \beta_1, \alpha_2 q \beta_2, \dots, \alpha_k q \beta_k$.

Le definizioni di linguaggi accettati e rifiutati restano uguali.

La classe dei linguaggi accettati da una macchina a $k$ nastri \`e un sovrainsieme della classe dei linguaggi accettati da una macchina di Turing con un solo nastro.
Ma vale anche il contrario: per dimostrarlo, vediamo che una macchina con $k$ nastri si pu\`o ``simulare'' con una macchina con un solo nastro.

Il contenuto dei $k$ nastri si pu\`o scrivere di seguito su un nastro solo.
Le $k$ testine si possono simulare inserendo dei nuovi simboli: se la $i$-esima testina \`e sulla lettera $a$, nel nastro unico sostituiamo a quella $a$ una lettera $\underline{a}_i$ segnata.

Una transizione si fa in due passaggi: nel primo passo si scorre l'intero nastro e si memorizzano i simboli segnati.
Per farlo, la macchina deve passare in uno stato che tiene conto dello stato della macchina simulato e di ciascuno di questi $k$ simboli.
Nel secondo passo si scorre nuovamente la stringa e per ogni simbolo segnato si esegue la transizione della macchina simulata, scrivendo quel che si deve scrivere e spostando la testina.

La versione non deterministica della macchina di Turing \`e, anche lei, equivalente alla macchina deterministica.
Una macchina \`e non deterministica se ha pi\`u scelte possibili da un certo stato, con un certo carattere in input.
Come al solito, la funzione di transizione va in un sottoinsieme dell'insieme delle parti del codominio della vecchia funzione di transizione.

Il linguaggio accettato da una macchina di Turing non deterministica \`e l'insieme delle parole per cui si arriva in uno stato di accettazione.
Il linguaggio rifiutato, invece, \`e il linguaggio delle parole per cui ogni stato finale in cui si arriva \`e di rifiuto.

Per simulare una macchina di Turing non deterministica con una macchina di Turing deterministica, si fa una visita BFS dell'albero delle computazioni della macchina di Turing.
\`E sufficiente stabilire l'ordine in cui le possibili mosse vengono controllate.
La macchina che simula avr\`a tre nastri, uno per l'input, uno per il lavoro, e un nastro guida per sapere qualche cammino seguire.

Se la macchina non deterministica si ferma, la deterministica che la simula non si ferma.

